{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuCYq4vCyYYQkTDueT/QmE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-unity-soccer/blob/main/%5BAtari%20Tennis%5D%20Reinforcement%20Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy1WJ1R-iP4V",
        "outputId": "c2ccc24d-267f-413b-e35e-b4b553707efb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting swig\n",
            "  Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.6 kB)\n",
            "Downloading swig-4.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium gymnasium[atari] stable_baselines3 pettingzoo multi-agent-ale-py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwt4C2URiRGM",
        "outputId": "43ff689a-169a-4a74-8f73-d4a79a4e8803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: pettingzoo in /usr/local/lib/python3.10/dist-packages (1.24.3)\n",
            "Collecting multi-agent-ale-py\n",
            "  Downloading multi-agent-ale-py-0.1.11.tar.gz (551 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m552.0/552.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.2.1)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.4.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3) (3.7.1)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3) (2024.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (6.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3) (1.3.0)\n",
            "Building wheels for collected packages: multi-agent-ale-py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvPXWTCHiO69"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "To run this code, make sure you have the necessary packages installed:\n",
        "\n",
        "pip install \"gymnasium[atari,accept-rom-license]\"\n",
        "pip install \"stable-baselines3[extra]\"\n",
        "\n",
        "This code trains an agent using PPO to play Atari Tennis.\n",
        "\"\"\"\n",
        "\n",
        "import gymnasium as gym\n",
        "from pettingzoo.atari import tennis_v3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.atari_wrappers import (\n",
        "    NoopResetEnv, MaxAndSkipEnv, EpisodicLifeEnv,\n",
        "    FireResetEnv, WarpFrame, ClipRewardEnv\n",
        ")\n",
        "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
        "import time\n",
        "\n",
        "def make_env(env_id):\n",
        "    \"\"\"\n",
        "    Creates and wraps the Atari environment.\n",
        "    \"\"\"\n",
        "    env = tennis_v3.env(render_mode=\"human\")\n",
        "    env.reset(seed=42)\n",
        "    #env = gym.make(env_id, render_mode='rgb_array')\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    env = MaxAndSkipEnv(env, skip=4)\n",
        "    env = EpisodicLifeEnv(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    env = ClipRewardEnv(env)\n",
        "    return env\n",
        "\n",
        "def main():\n",
        "    # Environment ID for Atari Tennis\n",
        "    env_id = \"ALE/Tennis-v5\"\n",
        "\n",
        "    # Number of parallel environments (increase for faster training)\n",
        "    num_envs = 8  # You can adjust this number\n",
        "\n",
        "    # Create the vectorized environment\n",
        "    env = DummyVecEnv([lambda: make_env(env_id) for _ in range(num_envs)])\n",
        "\n",
        "    # Stack frames (for temporal information)\n",
        "    env = VecFrameStack(env, n_stack=4)\n",
        "\n",
        "    # Create the PPO agent with CNN policy (since observations are images)\n",
        "    model = PPO(\"CnnPolicy\", env, verbose=1)\n",
        "\n",
        "    # Train the agent\n",
        "    total_timesteps = 10_000_000  # Adjust as needed\n",
        "    model.learn(total_timesteps=total_timesteps)\n",
        "\n",
        "    # Save the model\n",
        "    model.save(\"ppo_atari_tennis\")\n",
        "\n",
        "    # Close the environment\n",
        "    env.close()\n",
        "\n",
        "    # Evaluate the trained agent\n",
        "    evaluate_agent()\n",
        "\n",
        "def evaluate_agent():\n",
        "    # Create the environment for evaluation\n",
        "    env_id = \"ALE/Tennis-v5\"\n",
        "    env = gym.make(env_id, render_mode='human')\n",
        "\n",
        "    # Apply necessary wrappers\n",
        "    env = NoopResetEnv(env, noop_max=30)\n",
        "    env = MaxAndSkipEnv(env, skip=4)\n",
        "    env = EpisodicLifeEnv(env)\n",
        "    if 'FIRE' in env.unwrapped.get_action_meanings():\n",
        "        env = FireResetEnv(env)\n",
        "    env = WarpFrame(env)\n",
        "    env = ClipRewardEnv(env)\n",
        "\n",
        "    # Stack frames\n",
        "    env = DummyVecEnv([lambda: env])\n",
        "    env = VecFrameStack(env, n_stack=4)\n",
        "\n",
        "    # Load the trained model\n",
        "    model = PPO.load(\"ppo_atari_tennis\")\n",
        "\n",
        "    obs = env.reset()\n",
        "    while True:\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, rewards, dones, infos = env.step(action)\n",
        "        # Rendering is handled by the environment when render_mode='human'\n",
        "        if dones:\n",
        "            obs = env.reset()\n",
        "\n",
        "    env.close()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "haCywSvPiY3o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}