{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMgrXmfxtIYSbOup2g8VFju",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/rl-atari-tennis/blob/main/%5BAtari%20Tennis%5D%20Single-Agent%20Reinforcement%20Learning%20PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Atari Tennis] Single-Agent Reinforcement Learning"
      ],
      "metadata": {
        "id": "ob-2hGT3jNdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install swig"
      ],
      "metadata": {
        "id": "Fy1WJ1R-iP4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10b124e-7373-4a77-b1bc-2fa80c55cd63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: swig in /usr/local/lib/python3.10/dist-packages (4.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium gymnasium[atari] autorom"
      ],
      "metadata": {
        "id": "7U_qTvGlj2oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95eaa73-0b30-427a-c77e-b7c169fcfe2d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.10/dist-packages (0.29.1)\n",
            "Requirement already satisfied: autorom in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: shimmy<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from autorom) (8.1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autorom) (2.32.3)\n",
            "Requirement already satisfied: ale-py~=0.8.1 in /usr/local/lib/python3.10/dist-packages (from shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (0.8.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autorom) (2024.8.30)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]<1.0,>=0.1.0; extra == \"atari\"->gymnasium[atari]) (6.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!AutoROM --accept-license"
      ],
      "metadata": {
        "id": "Le7dztPUkVz4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08463b0d-97c4-4da9-cdbf-3b504c47fe73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoROM will download the Atari 2600 ROMs.\n",
            "They will be installed to:\n",
            "\t/usr/local/lib/python3.10/dist-packages/AutoROM/roms\n",
            "\n",
            "Existing ROMs will be overwritten.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install stable-baselines3"
      ],
      "metadata": {
        "id": "NmOqw4UAmAoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74535999-09bc-49a1-c342-f214fb04e995"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stable-baselines3 in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (0.29.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.4.0+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable-baselines3) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import torch\n",
        "import numpy\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_util import make_atari_env\n",
        "from stable_baselines3.common.vec_env import VecFrameStack\n",
        "from stable_baselines3.common.evaluation import evaluate_policy\n",
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "from stable_baselines3.common.vec_env import VecVideoRecorder\n",
        "from stable_baselines3.common.vec_env import VecTransposeImage\n",
        "import matplotlib.pyplot\n",
        "import matplotlib\n",
        "import os\n",
        "import gymnasium\n",
        "from importlib.metadata import version\n",
        "import time\n",
        "import google.colab.drive"
      ],
      "metadata": {
        "id": "o89JlEiexh1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python Version: {platform.python_version()}\")\n",
        "print(f\"Torch Version: {version('torch')}\")\n",
        "print(f\"Is Cuda Available: {torch.cuda.is_available()}\")\n",
        "print(f\"Cuda Version: {torch.version.cuda}\")\n",
        "print(f\"Gymnasium Version: {version('gymnasium')}\")\n",
        "print(f\"Numpy Version: {version('numpy')}\")\n",
        "print(f\"Stable Baselines3 Version: {version('stable_baselines3')}\")"
      ],
      "metadata": {
        "id": "KRrJSPuDiDN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7423bf8-7cde-440c-8ef2-1feccd1d0db9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python Version: 3.10.12\n",
            "Torch Version: 2.4.0+cu121\n",
            "Is Cuda Available: True\n",
            "Cuda Version: 12.1\n",
            "Gymnasium Version: 0.29.1\n",
            "Numpy Version: 1.26.4\n",
            "Stable Baselines3 Version: 2.3.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gdrive_path = \"/content/gdrive\"\n",
        "google.colab.drive.mount(gdrive_path, force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKxm5e7iGW_-",
        "outputId": "25dc3b45-2ab3-4334-bebd-39cfce06a0fa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rl_type = \"PPO\"\n",
        "env_str = \"ALE/Tennis-v5\"\n",
        "log_dir = \"{}/MyDrive/Finding Theta/logs/{}/{}\".format(gdrive_path,\n",
        "                                                       env_str,\n",
        "                                                       rl_type)"
      ],
      "metadata": {
        "id": "aR7w3BqcFiIO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\n",
        "# https://stable-baselines3.readthedocs.io/en/master/common/atari_wrappers.html\n",
        "env = make_atari_env(env_str, n_envs=1, seed=0)\n",
        "print(\"Observation Space Size: \", env.observation_space.shape)\n",
        "print('Actions Space: ', env.action_space)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T78JvLBVdmQO",
        "outputId": "4f5dd45a-cdf1-461e-e095-8c1999ebb79b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space Size:  (84, 84, 1)\n",
            "Actions Space:  Discrete(18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gymnasium.make(env_str)\n",
        "print(\"Observation Space Size: \", env.observation_space.shape)\n",
        "print('Actions Space: ', env.action_space)\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vCHAlsgg3lu",
        "outputId": "2cdbe4ed-d126-4fd1-8794-db81009d00c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space Size:  (210, 160, 3)\n",
            "Actions Space:  Discrete(18)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvPXWTCHiO69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7902398d-9c63-4ad8-e1d9-fe8b714efb3c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[35m  28%\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2,239,996/8,000,000 \u001b[0m [ \u001b[33m6:31:39\u001b[0m < \u001b[36m8:41:19\u001b[0m , \u001b[31m184 it/s\u001b[0m ]\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080\">  28%</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">╺━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #008000; text-decoration-color: #008000\">2,239,996/8,000,000 </span> [ <span style=\"color: #808000; text-decoration-color: #808000\">6:31:39</span> &lt; <span style=\"color: #008080; text-decoration-color: #008080\">8:41:19</span> , <span style=\"color: #800000; text-decoration-color: #800000\">184 it/s</span> ]\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create the Training Atari Tennis environment with appropriate wrappers\n",
        "env = make_atari_env(env_str, n_envs=4, seed=0)\n",
        "env = VecTransposeImage(env)\n",
        "env = VecFrameStack(env, n_stack=4)\n",
        "\n",
        "# Create the Evaluation Atari Tennis environment with appropriate wrappers\n",
        "env_val = make_atari_env(env_str, n_envs=1, seed=1)\n",
        "env_val = VecTransposeImage(env_val)\n",
        "env_val = VecFrameStack(env_val, n_stack=4)\n",
        "\n",
        "# Create Evaluation Callback\n",
        "# eval_freq - can cause learning instability if set to low\n",
        "eval_callback = EvalCallback(env_val,\n",
        "                             best_model_save_path=log_dir,\n",
        "                             log_path=log_dir,\n",
        "                             eval_freq=10_000,\n",
        "                             render=False,\n",
        "                             n_eval_episodes=5)\n",
        "\n",
        "# Initialize PPO\n",
        "# ent_coef - encourages exploration of other actins\n",
        "model = PPO(\"CnnPolicy\",\n",
        "            env,\n",
        "            verbose=0,\n",
        "            batch_size=256,\n",
        "            ent_coef=0.01)\n",
        "\n",
        "# Train the model\n",
        "model.learn(total_timesteps=8_000_000,\n",
        "            progress_bar=True,\n",
        "            callback=eval_callback)\n",
        "\n",
        "# Save the trained model\n",
        "model.save(os.path.join(log_dir, \"ppo_tennis\"))\n",
        "\n",
        "env.close()\n",
        "env_val.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Evaluation Atari Tennis environment with appropriate wrappers\n",
        "env_val = make_atari_env(env_str, n_envs=1, seed=1)\n",
        "env_val = VecTransposeImage(env_val)\n",
        "env_val = VecFrameStack(env_val, n_stack=4)\n",
        "\n",
        "# Load the best model\n",
        "best_model_path = os.path.join(log_dir, \"best_model.zip\")\n",
        "best_model = PPO.load(best_model_path, env=env_val)\n",
        "\n",
        "mean_reward, std_reward = evaluate_policy(best_model, env, n_eval_episodes=5)\n",
        "print(f\"Best Model - Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
        "\n",
        "# Record video of the best model playing Lunar Lander\n",
        "# TODO: Slow Down video execution to normal speeds (24 fps?)\n",
        "rec_val = VecVideoRecorder(env_val, log_dir,\n",
        "                       video_length=5000,\n",
        "                       record_video_trigger=lambda x: x == 0,\n",
        "                       name_prefix=\"best_model_atari_tennis_ppo\")\n",
        "\n",
        "rec_val.metadata[\"render_fps\"] = 24\n",
        "\n",
        "obs = rec_val.reset()\n",
        "for _ in range(5000):\n",
        "    action, _states = best_model.predict(obs)\n",
        "    obs, rewards, dones, info = rec_val.step(action)\n",
        "    rec_val.render()\n",
        "    if dones:\n",
        "      break\n",
        "\n",
        "env_val.close()\n",
        "rec_val.close()"
      ],
      "metadata": {
        "id": "OqwJT0bhcOu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the evaluations.npz file\n",
        "data = numpy.load(os.path.join(log_dir, \"evaluations.npz\"))\n",
        "\n",
        "# Extract the relevant data\n",
        "timesteps = data['timesteps']\n",
        "results = data['results']\n",
        "\n",
        "# Calculate the mean and standard deviation of the results\n",
        "mean_results = numpy.mean(results, axis=1)\n",
        "std_results = numpy.std(results, axis=1)\n",
        "\n",
        "# Plot the results\n",
        "matplotlib.pyplot.figure()\n",
        "matplotlib.pyplot.plot(timesteps, mean_results)\n",
        "matplotlib.pyplot.fill_between(timesteps,\n",
        "                               mean_results - std_results,\n",
        "                               mean_results + std_results,\n",
        "                               alpha=0.3)\n",
        "\n",
        "matplotlib.pyplot.xlabel('Timesteps')\n",
        "matplotlib.pyplot.ylabel('Mean Reward')\n",
        "matplotlib.pyplot.title(f\"PPO Performance on {env_str}\")\n",
        "matplotlib.pyplot.show()"
      ],
      "metadata": {
        "id": "Xisgp9SfcONO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "If3saIYUlM7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}